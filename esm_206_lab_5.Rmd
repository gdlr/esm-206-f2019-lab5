---
title: "ESM 206 Lab 5"
author: "Gabriel De La Rosa"
date: "10/28/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objectives:

- Getting counts for different groups
- Use {lubridate} to parse dates
- Find confidence intervals and do t-tests with t.test()
- Heatmap with geom_tile

```{r, include = FALSE}
# Attach packages

library(tidyverse)
library(here)
library(janitor)

```


```{r}
# Import lobster data

lobster_abundance <- read_csv(here::here("data", "lobster_abundance.csv"),
                              na = "-99999") %>% 
  clean_names()

```

Our data isn't in tidy format. Each lobster should have an individual row. The data is currently presented in a frequency table!

Let's expand this using the tidyr::uncount function for lobster counts.
This function drops NAs! Careful.

```{r}

lobster_tidy <- lobster_abundance %>%
  uncount(lobster_count)
```

Yay! Now each lobster has its own row. This is tidy format!

Let's explore our data a bit:

```{r}

ggplot(data = lobster_tidy, aes(x = site, y = size_mm)) +
  geom_jitter(aes(color = site),
              width = 0.2)

## This isn't super informative. Looks like they have similar central tendency, different spread. 
## Carp and IV look like they have outliers, maybe interesting.

ggplot(data = lobster_tidy, aes(x = site, y = size_mm)) +
  geom_violin(aes(color = site))

# Violin plots are still hard to figure out skew, normality...

ggplot(data = lobster_tidy, aes(x = size_mm)) +
  geom_histogram(aes(fill = site)) +
  facet_wrap(~site, scales = "free")

# scales = "free" changes individual scales for facets. Fine when looking at skew for sites.

# Histograms give us a good overview of skew.

```

These look relatively symmetrical, bell shaped, with one mode. 
Let's look at a quantile-quantile plot, where bin width exerts no influence on our data...

```{r}
# QQ plot with counts for each site...
# Need to specify what your sample mean is.

ggplot(data = lobster_tidy, aes(sample = size_mm)) +
  geom_qq(size = 0.5) +
  facet_wrap(~site, scales = "free")

```

Arroyo quemado looks normal. Carp looks like there's a few higher than expected outliers, same with IV. Mohawke also looks fairly normal. It's likely the histogram skewed the data with bin width. Naples looks very normal.

These are pretty normal across all groups!

But let's explore this data a bit more...like by date!


Use "lubridate" to parse date and times:
Always use lubridate:: because lubridate functions are redundant

Let's add a new column with 'mutate()' that contains a date with an actual date
```{r}

# Let's get R to recognize dates as a date.
# Date currently stored as month / day / year (mdy). Remember this!

lobster_date <-  lobster_tidy %>% 
  mutate(
    date_new = lubridate::mdy(date)
  )

# Both date format and variable class have changed.
```

Can we group this by months? Sure can!

Parse "date_new" column to get different pieces separated.
label = TRUE gives you month abbreviation

```{r}
lobster_parse_date <- lobster_date %>%
  mutate (
    obs_month = lubridate::month(date_new, label = TRUE)
  ) %>% 
  mutate (
    obs_year = lubridate::year(date_new)
  )

```

Nice!

Let's ask a few question about counts of lobsters. 

Count lobsters by different groupings...using dplyr::count!

Count calls on things using group_by, then counts those things in those groups.

Let's say I want to count the number of lobsters by year and month.

```{r}

lobster_ym <- lobster_parse_date %>%
  count(obs_year, obs_month)

lobster_ym

# What about counting for each site?

lobster_ysite <- lobster_parse_date %>% 
  count(obs_year, site)

lobster_ysite

# What about counting just for site?

lobster_site <- lobster_parse_date %>% 
  count(site)

lobster_site
```

This is super important when considering sample sizes.

How do we find numbers of observations in a summary table?
use group_by + summarize + n()

```{r}
lobster_summary <- lobster_parse_date %>%
  group_by (site) %>%
  summarize(
    mean_size = mean(size_mm, na.rm = TRUE),
    sd_size = sd(size_mm, na.rm = TRUE),
    sample_n = n()
  )

```

Count basically is better than tally. Don't listen to tally people. 

Let's start looking at some confidence intervals and t-tests.

T distribution accounts for increased uncertainty with small sample sizes and population uncertainty.

Use the "t.test()" function to find confidence intervals and perform t-tests
pull() stores values as a vector. Useful for some base r functions.

```{r}
# Let's find CI for lobster sizes at IV beach

ivee_lobsters <- lobster_tidy %>%
  filter(site == "IVEE") %>% 
  pull(size_mm)

t.test(ivee_lobsters)

```

Okay, but let's see if theres a significant difference in size between lobsters measured at naples and mowhawk reef

First, the tedious way...

```{r}
# Don't put just single means in! You need entire sample.

napl_sample <- lobster_tidy %>% 
  filter(site == "NAPL") %>% 
  pull(size_mm)

mohk_sample <- lobster_tidy %>% 
  filter(site == "MOHK") %>% 
  pull(size_mm)
  
mohk_napl_ttest <- t.test(mohk_sample, napl_sample)

mohk_napl_ttest

```

What does this mean? There is a 2.2 e -16 chance that if I took two random samples from a population with the same mean that I would get means this different. So, actually, what's more likely is that the two sample populations were initially different.


Inline variable referencing: 

Let's make a statement about the t-test.

Mean lobster size differed significantly between Mohawk and Naples reefs (df(`r mohk_napl_ttest$parameter`), t = `r mohk_napl_ttest$statistic`)

But there's an easier way!!

```{r}
# Create df with two groups you want to compare

lobster_2 <- lobster_tidy %>% 
  filter(site == c("NAPL", "MOHK"))

ttest_2 <- t.test(size_mm ~ site, data = lobster_2)

ttest_2


```

Now, let's make a geom_tile heatmap:
Using lobster_ysite



```{r}

ggplot(data = lobster_ysite, aes(x = obs_year, y = site)) +
  geom_tile(aes(fill = n))
```

